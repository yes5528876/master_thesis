{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Getting Started with Pre-trained SlowFast Models on Kinetcis400\n",
        "\n",
        "`Kinetics400 <https://deepmind.com/research/open-source/kinetics>`_  is an action recognition dataset\n",
        "of realistic action videos, collected from YouTube. With 306,245 short trimmed videos\n",
        "from 400 action categories, it is one of the largest and most widely used dataset in the research\n",
        "community for benchmarking state-of-the-art video action recognition models.\n",
        "\n",
        "`SlowFast <https://arxiv.org/abs/1812.03982>`_ is a new 3D video classification model,\n",
        "aiming for best trade-off between accuracy and efficiency. It proposes two branches,\n",
        "fast branch and slow branch, to handle different aspects in a video.\n",
        "Fast branch is to capture motion dynamics by using many but small video frames.\n",
        "Slow branch is to capture fine apperance details by using few but large video frames.\n",
        "Features from two branches are combined using lateral connections.\n",
        "\n",
        "In this tutorial, we will demonstrate how to load a pre-trained SlowFast model from `gluoncv-model-zoo`\n",
        "and classify a video clip from the Internet or your local disk into one of the 400 action classes.\n",
        "\n",
        "## Step by Step\n",
        "\n",
        "We will try out a pre-trained SlowFast model on a single video clip.\n",
        "\n",
        "First, please follow the `installation guide <../../index.html#installation>`__\n",
        "to install ``MXNet`` and ``GluonCV`` if you haven't done so yet.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jylong/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/home/jylong/.local/lib/python3.6/site-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.9.1` and `torch==1.6.0+cpu` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n",
            "  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "from mxnet import gluon, nd, image\n",
        "from mxnet.gluon.data.vision import transforms\n",
        "from gluoncv.data.transforms import video\n",
        "from gluoncv import utils\n",
        "from gluoncv.model_zoo import get_model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we download the video and extract a 64-frame clip from it.\n",
        "Note that SlowFast has two branches, which require different inputs.\n",
        "The fast branch needs more frames, which we sample every other frame (stride=2).\n",
        "The slow branch needs less frames, which we sample every 16th frame (stride=16).\n",
        "In the end, we have 32 frames as the input to the fast branch and 4 frames to the slow branch.\n",
        "Hence, the final input to the whole network is a clip of 36 frames.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading abseiling_k400.mp4 from https://github.com/bryanyzhu/tiny-ucf101/raw/master/abseiling_k400.mp4...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:00<00:00, 3460.12KB/s]\n"
          ]
        }
      ],
      "source": [
        "from gluoncv.utils.filesystem import try_import_decord\n",
        "decord = try_import_decord()\n",
        "\n",
        "url = 'https://github.com/bryanyzhu/tiny-ucf101/raw/master/abseiling_k400.mp4'\n",
        "video_fname = utils.download(url)\n",
        "vr = decord.VideoReader(video_fname)\n",
        "fast_frame_id_list = range(0, 64, 2)\n",
        "slow_frame_id_list = range(0, 64, 16)\n",
        "frame_id_list = list(fast_frame_id_list) + list(slow_frame_id_list)\n",
        "video_data = vr.get_batch(frame_id_list).asnumpy()\n",
        "clip_input = [video_data[vid, :, :, :] for vid, _ in enumerate(frame_id_list)]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we define transformations for the video clip.\n",
        "This transformation function does three things:\n",
        "center crop each image to 224x224 in size,\n",
        "transpose it to ``num_channels*num_frames*height*width``,\n",
        "and normalize with mean and standard deviation calculated across all ImageNet images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video data is downloaded and preprocessed.\n"
          ]
        }
      ],
      "source": [
        "transform_fn = video.VideoGroupValTransform(size=224, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "clip_input = transform_fn(clip_input)\n",
        "clip_input = np.stack(clip_input, axis=0)\n",
        "clip_input = clip_input.reshape((-1,) + (36, 3, 224, 224))\n",
        "clip_input = np.transpose(clip_input, (0, 2, 1, 3, 4))\n",
        "print('Video data is downloaded and preprocessed.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we load a pre-trained SlowFast model with ResNet50 as backbone.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading /home/jylong/.mxnet/models/slowfast_4x16_resnet50_kinetics400-9d650f51.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/slowfast_4x16_resnet50_kinetics400-9d650f51.zip...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 134964/134964 [00:26<00:00, 5169.54KB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "slowfast_4x16_resnet50_kinetics400 model is successfully loaded.\n"
          ]
        }
      ],
      "source": [
        "model_name = 'slowfast_4x16_resnet50_kinetics400'\n",
        "net = get_model(model_name, nclass=400, pretrained=True)\n",
        "print('%s model is successfully loaded.' % model_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we prepare the video clip and feed it to the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The input video clip is classified to be\n",
            "\t[abseiling], with probability 0.996.\n",
            "\t[rock_climbing], with probability 0.004.\n",
            "\t[ice_climbing], with probability 0.000.\n",
            "\t[paragliding], with probability 0.000.\n",
            "\t[climbing_a_rope], with probability 0.000.\n"
          ]
        }
      ],
      "source": [
        "pred = net(nd.array(clip_input))\n",
        "\n",
        "classes = net.classes\n",
        "topK = 5\n",
        "ind = nd.topk(pred, k=topK)[0].astype('int')\n",
        "print('The input video clip is classified to be')\n",
        "for i in range(topK):\n",
        "    print('\\t[%s], with probability %.3f.'%\n",
        "          (classes[ind[i].asscalar()], nd.softmax(pred)[0][ind[i]].asscalar()))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that our pre-trained model predicts this video clip\n",
        "to be ``abseiling`` action with high confidence.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Step\n",
        "\n",
        "If you would like to dive deeper into training SlowFast models on ``Kinetics400``,\n",
        "feel free to read the next `tutorial on Kinetics400 <dive_deep_slowfast_kinetics400.html>`__.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
